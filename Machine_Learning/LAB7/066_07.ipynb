{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "066_07.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWLXQplZAyK2",
        "colab_type": "text"
      },
      "source": [
        "CE066-Jaydeep Mahajan- ML- LAB 7 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTy_SaDQ7hA7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import libraries\n",
        "import nltk\n",
        "import re\n",
        "import string\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from nltk.corpus import twitter_samples\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "from __future__ import absolute_import, division, print_function"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYvu8fz5Bvza",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "ddcc948c-a6ea-46aa-a25a-de9656090e27"
      },
      "source": [
        "# download twitter_samples and stopwords dataset\n",
        "nltk.download('twitter_samples')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package twitter_samples to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-DDHD8jBxdF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function for preprocessing task and set train data\n",
        "def process_tweet(tweet):\n",
        "  stemmer = PorterStemmer()\n",
        "  stopwords_english = stopwords.words('english')\n",
        "  tweet = re.sub(r'\\$\\w*', '', tweet)\n",
        "  tweet = re.sub(r'^RT[\\s]+', '', tweet)\n",
        "  tweet = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet)\n",
        "  tweet = re.sub(r'#', '', tweet)\n",
        "\n",
        "  tokenizer = TweetTokenizer(preserve_case=False,strip_handles=True,reduce_len=True)\n",
        "  tweet_tokens = tokenizer.tokenize(tweet)\n",
        "  tweets_clean = []\n",
        "  for word in tweet_tokens:\n",
        "    if (word not in stopwords_english and word not in string.punctuation):\n",
        "      stem_word = stemmer.stem(word)\n",
        "      tweets_clean.append(stem_word)\n",
        "  return tweets_clean\n",
        "\n",
        "def build_freqs(tweets, ys):\n",
        "  yslist = np.squeeze(ys).tolist()\n",
        "  freqs = {}\n",
        "  for y, tweet in zip(yslist, tweets):\n",
        "    for word in process_tweet(tweet):\n",
        "      pair = (word, y)\n",
        "      if pair in freqs:\n",
        "        freqs[pair]+=1\n",
        "      else:\n",
        "        freqs[pair]=1\n",
        "  return freqs\n",
        "\n",
        "def extract_features(tweet, freqs):\n",
        "  word_list = process_tweet(tweet)\n",
        "  x = np.zeros((1,2), dtype=np.float32)\n",
        "  for word in word_list:\n",
        "    if (word,1) in freqs:\n",
        "      x[0,0]+=freqs[word,1]\n",
        "    if (word,0) in freqs:\n",
        "      x[0,1]+=freqs[word,0]\n",
        "  assert(x.shape==(1,2))\n",
        "  return x "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALQpKY8KB1cd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "78205a81-1789-4bb4-9d09-cc9d7d09770f"
      },
      "source": [
        "# sample of preprocessed tweet\n",
        "processed_tweet = process_tweet(\"@Amazon is always #good company\")\n",
        "print(processed_tweet)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['alway', 'good', 'compani']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJafcIDtCDQI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get the positive and negative tweets and create dataset\n",
        "all_positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
        "all_negative_tweets = twitter_samples.strings('negative_tweets.json')\n",
        "\n",
        "test_pos = all_positive_tweets[3000:]\n",
        "train_pos = all_positive_tweets[:3000]\n",
        "test_neg = all_negative_tweets[3000:]\n",
        "train_neg = all_negative_tweets[:3000]\n",
        "\n",
        "train_x = train_pos + train_neg\n",
        "test_x = test_pos + test_neg\n",
        "train_y = np.append(np.ones((len(train_pos), 1),np.int64), np.zeros((len(train_neg), 1),np.int64), axis=0)\n",
        "test_y = np.append(np.ones((len(test_pos), 1),np.int64), np.zeros((len(test_neg), 1),np.int64), axis=0)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwqeiPf2CGLz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f7f04073-a6ad-445d-b9a7-1a855e884256"
      },
      "source": [
        "# Get word frequencies for positive and negative sentiment\n",
        "freqs = build_freqs(train_x,train_y)\n",
        "print(\"type(freqs) = \" + str(type(freqs)))\n",
        "print(\"len(freqs) = \" + str(len(freqs.keys())))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "type(freqs) = <class 'dict'>\n",
            "len(freqs) = 9326\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxEdHP_TCITh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define parameters\n",
        "num_classes = 2 # 1 or 0\n",
        "num_features = 2 # positive and negative freqs\n",
        "learning_rate =  0.001\n",
        "training_steps = 1000\n",
        "batch_size = 256\n",
        "display_step = 50"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxvE0GLFCLo7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "6e82d89e-1ad4-4cb2-8e1a-d28a5aa5c2a0"
      },
      "source": [
        "# Get the frequencies of positive and negative word for 2 samples\n",
        "sample_1 = extract_features(train_x[0], freqs)\n",
        "print(\"sample 1 : \", sample_1)\n",
        "sample_2 = extract_features(train_x[4010], freqs)\n",
        "print(\"sample 2 : \", sample_2)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample 1 :  [[2276.   47.]]\n",
            "sample 2 :  [[  45. 2822.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBFADleKCOlM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "089555c7-61f6-4a47-e188-b40e6c370907"
      },
      "source": [
        "# Format X_train and X_test\n",
        "X_train = np.zeros((len(train_x),2),dtype=np.float32)\n",
        "X_test = np.zeros((len(test_x),2),dtype=np.float32)\n",
        "for i in range(len(train_x)):\n",
        "  X_train[i,:] = extract_features(train_x[i],freqs)\n",
        "for i in range(len(test_x)):\n",
        "  X_test[i,:] = extract_features(test_x[i],freqs)\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "Y_train = train_y\n",
        "Y_test = test_y\n",
        "print(\"Train sample : \",X_train[0],Y_train[0])\n",
        "print(\"Test sample : \",X_test[1500],Y_test[1500])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train sample :  [ 1.0975696  -0.91117305] [1]\n",
            "Test sample :  [ 1.2294407  -0.74473023] [1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMqrPUt1CRUw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Intialize weight and bias\n",
        "W = tf.Variable(tf.ones([num_features, num_classes]), name=\"weight\")\n",
        "b = tf.Variable(tf.zeros([num_classes]), name=\"bias\")\n",
        "\n",
        "# Use tf.data API to shuffle and batch data.\n",
        "train_data=tf.data.Dataset.from_tensor_slices((X_train,Y_train))\n",
        "train_data=train_data.repeat().shuffle(5000).batch(batch_size).prefetch(1)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUVqRSPaCUIX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Main function for perform logistic regression\n",
        "def logistic_regression(x,W,b):\n",
        "  return tf.nn.sigmoid(tf.matmul(x,W) + b)\n",
        "\n",
        "def cross_entropy(y_pred,y_true):\n",
        "  y_true = tf.one_hot(y_true, depth=num_classes)\n",
        "  y_pred = tf.clip_by_value(y_pred,1e-9,1.)\n",
        "  return tf.reduce_mean(-tf.reduce_sum(y_true*tf.math.log(y_pred)))\n",
        "\n",
        "def accuracy(y_pred, y_true):\n",
        "  correct_prediction = tf.equal(tf.argmax(y_pred, 1), tf.cast(y_true, tf.int64))\n",
        "  return tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "\n",
        "def run_optimization(x,y):\n",
        "  with tf.GradientTape() as g:\n",
        "    pred = logistic_regression(x,W,b)\n",
        "    loss = cross_entropy(pred,y)\n",
        "  gradients = g.gradient(loss,[W,b])\n",
        "  optimizer = tf.optimizers.SGD(learning_rate)\n",
        "  optimizer.apply_gradients(zip(gradients, [W,b]))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCIGH9zICXsb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "0d9c9278-8ad4-4d32-d321-c22a90bb5314"
      },
      "source": [
        "# Train model for given number of step\n",
        "for step, (batch_x, batch_y) in enumerate(train_data.take(training_steps), 1):\n",
        "  run_optimization(batch_x, batch_y)\n",
        "  if step % display_step == 0:\n",
        "        pred = logistic_regression(batch_x,W,b)\n",
        "        loss = cross_entropy(pred, batch_y)\n",
        "        acc = accuracy(pred, batch_y)\n",
        "        print(\"step: %i, loss: %f, accuracy: %f\" % (step, loss, acc))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "step: 50, loss: 0.028325, accuracy: 0.432709\n",
            "step: 100, loss: 0.047213, accuracy: 0.452637\n",
            "step: 150, loss: 0.129363, accuracy: 0.494263\n",
            "step: 200, loss: 0.015692, accuracy: 0.580933\n",
            "step: 250, loss: 0.032502, accuracy: 0.591797\n",
            "step: 300, loss: 0.017747, accuracy: 0.525543\n",
            "step: 350, loss: 0.022523, accuracy: 0.513062\n",
            "step: 400, loss: 0.511682, accuracy: 0.432709\n",
            "step: 450, loss: 0.195987, accuracy: 0.381348\n",
            "step: 500, loss: 0.038066, accuracy: 0.467102\n",
            "step: 550, loss: 0.016692, accuracy: 0.571838\n",
            "step: 600, loss: 0.016760, accuracy: 0.539917\n",
            "step: 650, loss: 0.011609, accuracy: 0.609009\n",
            "step: 700, loss: 0.017970, accuracy: 0.534241\n",
            "step: 750, loss: 0.022494, accuracy: 0.466431\n",
            "step: 800, loss: 0.026300, accuracy: 0.381714\n",
            "step: 850, loss: 0.020431, accuracy: 0.419281\n",
            "step: 900, loss: 0.036609, accuracy: 0.507080\n",
            "step: 950, loss: 0.013255, accuracy: 0.586975\n",
            "step: 1000, loss: 0.010869, accuracy: 0.659302\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HK4MSRFCafM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "fc1f194e-6c67-4742-d5c0-552a289c4759"
      },
      "source": [
        "#Final weight\n",
        "print(\"Weight : \")\n",
        "print(W)\n",
        "#Final bias\n",
        "print(\"Bias : \")\n",
        "print(b)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Weight : \n",
            "<tf.Variable 'weight:0' shape=(2, 2) dtype=float32, numpy=\n",
            "array([[-0.67513263, -1.3009712 ],\n",
            "       [-0.8364491 , -1.6109239 ]], dtype=float32)>\n",
            "Bias : \n",
            "<tf.Variable 'bias:0' shape=(2,) dtype=float32, numpy=array([14.573064, 21.138458], dtype=float32)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6Lj09R1Cc5-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9d36c771-70f7-46d2-d9be-fc9935af0ca3"
      },
      "source": [
        "pred = logistic_regression(X_test,W,b)\n",
        "print(\"Test accuracy: %f\" % accuracy(pred,Y_test))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy: 0.500000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gU_ar9g1Cf5z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}